{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InternetFirewallSupervisedLearning\n",
    "## Author: Tijs van Lieshout\n",
    "\n",
    "Predicting the Internet Firewall action based on log info. Supervised Learning Assignment for Master DSLS.\n",
    "\n",
    "### Data availability:\n",
    "- [Direct link](https://archive.ics.uci.edu/ml/machine-learning-databases/00542/log2.csv)\n",
    "- [Archive link with some info](https://archive.ics.uci.edu/ml/datasets/Internet+Firewall+Data)\n",
    "- [F. Ertam and M. Kaya, \"Classification of firewall log files with multiclass support vector machine,\" 2018 6th International Symposium on Digital Forensic and Security (ISDFS), 2018, pp. 1-4, doi: 10.1109/ISDFS.2018.8355382.](https://doi.org/10.1109/ISDFS.2018.8355382)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1. Classes to predict (Actions)\n",
    "\n",
    "|   Action   |                                                               Description                                                              |\n",
    "|:----------:|:--------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| Allow      | Allows the internet traffic.                                                                                                           |\n",
    "| Deny       | Blocks traffic and enforces the default Deny Action defined for the application that is being denied.                                  |\n",
    "| Drop       | Silently drops the traffic; for an application, it overrides the default deny action. A TCP reset is not sent to the host/application. |\n",
    "| Reset-Both | Sends a TCP reset to both the client-side and server-sidedevices.                                                                      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"log2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allow, deny, drop, reset_both = df['Action'].value_counts()\n",
    "print('Number of allowed logs: ', allow)  \n",
    "print('Number of denied logs: ', deny)\n",
    "print('Number of dropped logs: ', drop)  \n",
    "print('Number of reset-both logs: ', reset_both) \n",
    "\n",
    "print('\\n')\n",
    "print('% of allowed logs', round(allow / len(df) * 100, 1), '%')\n",
    "print('% of denied logs', round(deny / len(df) * 100, 1), '%')\n",
    "print('% of dropped logs', round(drop / len(df) * 100, 1), '%')\n",
    "print('% of reset-both logs', round(reset_both / len(df) * 100, 1), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Action'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty unbalanced classes to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data\n",
    "df.isnull().sum() \n",
    "# no missing data, no imputation needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "description = df.groupby(['Action']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df.corr().abs()\n",
    "sns.heatmap(c, cmap=sns.color_palette(\"Blues\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Bytes Sent', 'Bytes Received', 'pkts_sent' and 'pkts_received' can be discarded as Bytes and Packets are the total of the two pairs respectively.\n",
    "\n",
    "I am also going to discard packets for bytes as it is highly correlated. I'll keep Bytes since it is more detailed than packets (1 packet consists of multiple bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the port variables should not be seen as continous, but probably are interesting to see the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.displot(df, x=\"Source Port\", hue=\"Action\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description['Source Port']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Actions of drop seem to happen in high source ports (minimum 49156). Reset-both Source Port minimum is 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.displot(df, x=\"Destination Port\", hue=\"Action\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description['Destination Port']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most actions seem to have a very low destination port. All drop actions are done on Destination Port 445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x=\"NAT Source Port\", hue=\"Action\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description['NAT Source Port']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allowed actions seme to be uniformly distributed over NAT Source Ports. All dropped NAT Source Ports are equal to 0. Most deny and reset-both actions have NAT Source Ports of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x=\"NAT Destination Port\", hue=\"Action\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description['NAT Destination Port']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allowed actions seme to be uniformly distributed over NAT Destination Ports. All dropped NAT Destination Ports are equal to 0. Most deny and reset-both actions have NAT Destination Ports of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Source Port', \n",
    "        'Destination Port', \n",
    "        'NAT Source Port', \n",
    "        'NAT Destination Port', \n",
    "        'Bytes', \n",
    "        'Elapsed Time (sec)']\n",
    "df_features = df[cols].rename(columns={'Source Port':'source_port',\n",
    "                                       'Destination Port':'destination_port', \n",
    "                                       'NAT Source Port':'nat_source_port', \n",
    "                                       'NAT Destination Port':'nat_destination_port',\n",
    "                                       'Bytes':'bytes',\n",
    "                                       'Elapsed Time (sec)':'elapsed_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df_features.corr().abs()\n",
    "sns.heatmap(c, cmap=sns.color_palette(\"Blues\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = np.array(df['Action'].replace({'allow':0,'deny':1,'drop':2, 'reset-both':3}))\n",
    "X = np.array(df_features)\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalize(X):\n",
    "    scalar = StandardScaler()\n",
    "    scalar = scalar.fit(X)\n",
    "    X = scalar.transform(X)\n",
    "    return X\n",
    "\n",
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "#split\n",
    "test_size = 0.4\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "\n",
    "#cross validation\n",
    "cv = ShuffleSplit(n_splits=100, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate(y_test, y_pred, X_test, clf):\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "\n",
    "def plot_learning_curves(model, X_train, y_train, X_val, y_val, training_sizes=range(999, len(X_train), 1000)):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        model:pipeline object\n",
    "        X_train, y_train: trainingsdata\n",
    "        X_val, y_val: test data\n",
    "    \"\"\"\n",
    "    train_errors, val_errors = [], []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for m in training_sizes:\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n",
    "        val_errors.append(mean_squared_error(y_val_predict, y_val))\n",
    "\n",
    "    plt.plot(training_sizes, np.sqrt(train_errors),\n",
    "             \"r-+\", linewidth=2, label=\"trainingsdata\")\n",
    "    plt.plot(training_sizes, np.sqrt(val_errors), \n",
    "             \"b-\", linewidth=3, label=\"validationdata\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14)   \n",
    "    plt.xlabel(\"Training set size\", fontsize=14) \n",
    "    plt.ylabel(\"RMSE\", fontsize=14)     \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lg = LogisticRegression(max_iter=1000)\n",
    "lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "y_pred = lg.predict(X_test)\n",
    "evaluate(y_test, y_pred, X_test, lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(lg, X_train, y_train, X_test, y_test, range(1999, len(X_train), 2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "y_pred = dt.predict(X_test)\n",
    "evaluate(y_test, y_pred, X_test, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function: linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_lin = SVC(kernel='linear')\n",
    "svm_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_lin.predict(X_test)\n",
    "evaluate(y_test, y_pred, X_test, svm_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(svm_lin, X_train, y_train, X_test, y_test, range(4999, len(X_train), 5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function: poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_poly = SVC(kernel='poly')\n",
    "svm_poly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_poly.predict(X_test)\n",
    "evaluate(y_test, y_pred, X_test, svm_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(svm_poly, X_train, y_train, X_test, y_test, range(4999, len(X_train), 5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function: RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "svm_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_rbf.predict(X_test)\n",
    "evaluate(y_test, y_pred, X_test, svm_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(svm_rbf, X_train, y_train, X_test, y_test, range(4999, len(X_train), 5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function: sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_sig = SVC(kernel='sigmoid')\n",
    "svm_sig.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_sig.predict(X_test)\n",
    "evaluate(y_test, y_pred, X_test, svm_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(svm_sig, X_train, y_train, X_test, y_test, range(4999, len(X_train), 5000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
